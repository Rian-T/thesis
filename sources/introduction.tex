%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\label{chap:intro}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
  \begin{minipage}{0.75\textwidth}
    \begin{small}
      \raggedright
      \setlength{\parindent}{0pt}

      ``The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin. [\ldots]
      We should build in only the meta-methods that can find and capture this arbitrary complexity. [\ldots]
      The eventual success is tinged with bitterness, and often incompletely digested.''
    \end{small}

    \begin{flushright}
      - Richard S. Sutton, \textit{The Bitter Lesson}
    \end{flushright}
  \end{minipage}
\end{center}

Healthcare has been one of the earliest and most prominent application domains for artificial intelligence. Use cases range from diagnostic support to medical record management, cohort selection, report generation, and clinical information extraction.

As early as the 1970s, MYCIN, the iconic expert system developed at Stanford, diagnosed bacterial infections and recommended antibiotics. It already achieved performance comparable to human specialists in its narrow domain. INTERNIST-1, later known as CADUCEUS, tackled internal medicine diagnosis across hundreds of diseases. However, these systems relied on explicit rules and static knowledge bases, which limited their ability to handle the complexity and variability of real-world medical data. They were rigid and required constant maintenance to keep up with medical advances. Building such systems demanded expensive medical experts to annotate clinical data and write rules by hand.

With the rise of machine learning in the 1990s and 2000s, data-driven approaches began to dominate healthcare AI. Supervised and unsupervised learning algorithms trained models directly from data. The interpretability of rule-based systems was traded for the performance of deep neural networks capable of capturing complex patterns. R2 ImageChecker (1998) became the first FDA-approved computer-aided detection system for mammography, using neural networks to spot suspicious microcalcifications. PAPNET applied neural networks to cytological screening for cervical cancer.

Then came the scaling era. The recipe became simple: pretrain a language model on billions of words of raw text, then fine-tune on the target task. This approach routinely outperformed systems built with years of domain expertise. The need for expensive annotation, hand-crafted rules, and curated knowledge bases faded, beaten by data and compute.

Despite healthcare offering many structured and curated knowledge bases such as UMLS, SNOMED-CT, and RxNorm, experience has shown that general-purpose language models pretrained on massive unstructured data outperform approaches based on domain-specific rules and knowledge bases. It seems our models cannot effectively integrate these structured resources, or perhaps these knowledge bases do not cover the full complexity and variability of medical knowledge as it is used in practice.

However, healthcare faces a limitation that other domains do not: the confidentiality and scarcity of annotated clinical data. Medical data is sensitive and difficult to obtain in large quantities for model training. Works adapting language models to the medical domain often rely on public data such as PubMed or patient forums, but these do not always reflect the real clinical language used in electronic health records. The clinical domain has unique jargon, abbreviations, and writing styles that differ from general medical texts. Moreover, while MIMIC exists in the United States, public clinical datasets remain scarce in other countries such as France.

This leads to a fundamental problem: the paradigm that has won is pretraining at scale, but in healthcare we lack massive public clinical data to pretrain language models. Can we find new ways to exploit public data for pretraining language models adapted to the clinical domain, without using sensitive clinical data?
